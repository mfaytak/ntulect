<?xml version="1.0" encoding="utf-8"?>

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"

 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">

<head>
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/solid.css" integrity="sha384-VGP9aw4WtGH/uPAOseYxZ+Vz/vaTb1ehm1bwx92Fm8dTrE+3boLfF1SpAtB1z7HW" crossorigin="anonymous">

  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/fontawesome.css" integrity="sha384-1rquJLNOM3ijoueaaeS5m+McXPJCGdr5HcA03/VHXxcp2kX2sUrQDmFc3jR5i/C7" crossorigin="anonymous">
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />

  <meta http-equiv="Content-Style-Type" content="text/css" />

  <meta name="generator" content="pandoc" />

  <meta name="author" content="Matthew Faytak University at Buffalo" />

  <title>NTU lectures (1)</title>

  <style type="text/css">

      code{white-space: pre-wrap;}

      span.smallcaps{font-variant: small-caps;}

      span.underline{text-decoration: underline;}

      div.column{display: inline-block; vertical-align: top; width: 50%;}

  </style>

  <link rel="stylesheet" type="text/css" media="screen, projection, print"

    href="assets/styles/slidy.css" />

  <script src="assets/scripts/slidy.js"

    charset="utf-8" type="text/javascript"></script>

</head>

<body>

<div class="slide titlepage">

  <h1 class="title">NTU lectures (1)</h1>

  <p class="author">

Matthew Faytak<br/>University at Buffalo

  </p>

  <p class="date"><img src="./assets/media/UB_Stacked_Small.png" width="200"> <img src="./assets/media/ntu-logo.png" width="200"><br/><img src="./assets/media/qr1.png" width="170"></p>

</div>

<div id="about-me" class="title-slide slide section level1"><h1>About me</h1></div><div id="about-me-1" class="slide section level2">

<h1>About me</h1>

<p>Matthew Faytak [ˈfeɪˌtæk], assistant professor in Linguistics at the University at Buffalo (State Univ. of New York) since mid-2021</p>

<ul>

<li>PhD UC Berkeley 2018</li>

<li>Postdoc UCLA 2018-2021</li>

</ul>

<p>Pronouns he/him/his, they/them/their (in the sense of 他)</p>

</div><div id="about-me-2" class="slide section level2">

<h1>About me</h1>

<p>My expertise is in articulatory phonetics</p>

<ul>

<li>Specialization in ultrasound tongue imaging</li>

<li>I have worked on languages of China and Cameroon, plus English and French</li>

<li>I can use French and Standard Chinese

<ul>

<li>… just not well enough to give this lecture in</li>

</ul></li>

</ul>

<p>Additional interests in phonetic typology, sound change, and phonological structure</p>

</div>

<div id="the-format-of-these-lectures" class="title-slide slide section level1"><h1>The format of these lectures</h1></div><div id="slidy-slides" class="slide section level2">

<h1>Slidy slides</h1>

<p>These lecture slides are hosted in HTML format on my personal site</p>

<ul>

<li>Displays slide by slide by default; use arrow keys or click to navigate</li>

<li>“C” key displays table of contents</li>

<li>“A” key shows all slides in order</li>

<li>“P” key prints slides</li>

</ul>

<p>Each linked by a QR code (see title slide)</p>

</div><div id="annotations" class="slide section level2">

<h1>Annotations</h1>

<p>We will highlight key terms <strong>like this</strong></p>

<p>Emphasis looks <em>like this</em></p>

<p>We will cover Python code, and when presented in slides it will look <code>like_this()</code></p>

<p>In-text references are included as small text <span class="cite">Like &amp; This (1980)</span></p>

<p>In-text external links look <a href="https://www.youtube.com/watch?v=dQw4w9WgXcQ">like this</a></p>

</div>

<div id="about-this-course" class="title-slide slide section level1"><h1>About this course</h1></div><div id="about-this-course-1" class="slide section level2">

<h1>About this course</h1>

<p>Two main areas:</p>

<ul>

<li>Ultrasound as a tool for phonetics and speech science</li>

<li><strong>Dimensionality reduction</strong> as one of several ways of handling ultrasound data

<ul>

<li>Taking many dimensions (whole image) and producing simpler numerical measures</li>

</ul></li>

</ul>

<p>Helps us to solve a conundrum:</p>

<ul>

<li>Ultrasound is non-invasive, well-suited to field situations, relatively inexpensive and speaker-friendly</li>

<li>… but creates very complex, noisy data, which normally requires labor-intensive post-processing</li>

</ul>

</div><div id="about-this-course-2" class="slide section level2">

<h1>About this course</h1>

<p>Specific topics covered will include:</p>

<ul>

<li><strong>Features</strong> in acoustic and articulatory phonetics analysis</li>

<li><strong>Feature selection</strong> and <strong>feature extraction</strong> in phonetics</li>

<li>Dimensionality reduction as a type of feature extraction</li>

<li>Ultrasound data and typical processing methods</li>

<li><strong>Eigentongue</strong> method and derived methods</li>

</ul>

<p>Interactive Python notebooks for:</p>

<ul>

<li><strong>Principal component analysis</strong> of a general data set</li>

<li>Two case studies from my own work (on Shanghai Mandarin and Suzhou Wu)</li>

</ul>

</div><div id="the-rest-of-this-lecture" class="slide section level2">

<h1>The rest of <em>this</em> lecture</h1>

<p><strong>Features</strong> and <strong>feature selection</strong> in phonetics (speech production)</p>

<ul>

<li>Major way we arrive at predictive features for research purposes</li>

<li>Underlying research philosophy</li>

<li>Limits and advantages of this approach</li>

</ul>

</div>

<div id="feature-selection" class="title-slide slide section level1"><h1>Feature selection</h1></div><div id="features" class="slide section level2">

<h1>Features</h1>

<p>Not meant in the phonological sense: a <strong>feature</strong> is a property of some phenomenon that can be measured <span class="cite">Liu (2011)</span></p>

<ul>

<li>Observations of study phenomena are made in terms of their features</li>

<li>We must know <em>which</em> features to observe when conducting research</li>

<li>Cannot observe all simultaneously</li>

</ul>

</div><div id="feature-selection-1" class="slide section level2">

<h1>Feature selection</h1>

<p>This process we undertake is <strong>feature selection</strong>: picking a subset of available features <span class="cite">Liu (2011)</span></p>

<ul>

<li>Often based on prior knowledge of the phenomenon</li>

<li>A way to bring the number of features down to a reasonable level</li>

</ul>

<p>Feature selection is labor-intensive but is fundamental to science and engineering <span class="cite">Guyon &amp; Elisseeff (2003); Cai et al. (2018)</span>, with clear benefits for researchers:</p>

<ul>

<li>Improve performance of predictor variables, by selecting the right ones</li>

<li>Speed up computation and analysis to practical levels</li>

<li>Develop a <em>theory-driven</em> understanding of the phenomenon being studied</li>

</ul>

</div>

<div id="feature-selection-in-phonetics" class="title-slide slide section level1"><h1>Feature selection in phonetics</h1></div><div id="feature-selection-in-phonetics-1" class="slide section level2">

<h1>Feature selection in phonetics</h1>

<p>The signal resulting from speech is complex and time varying, so phoneticians have long been concerned with questions of feature selection</p>

<ul>

<li>Measure particular acoustic properties</li>

<li>Measure certain aspects of articulation</li>

<li>Record particular aspects of response to stimuli</li>

<li>As opposed to offering <em>gestalt</em> impression of a recording</li>

</ul>

</div><div id="feature-selection-in-phonetics-2" class="slide section level2">

<h1>Feature selection in phonetics</h1>

<p>Some general criteria of a good feature in speech production research:</p>

<ul>

<li>Good performance against known categories (i.e. phonemic contrasts)</li>

<li>Perceptual relevance</li>

<li>Practical to measure</li>

</ul>

<p>The challenge: figuring out what feature(s) to select</p>

<ul>

<li>Often takes years of research, as we will see</li>

</ul>

</div><div id="voice-onset-time" class="slide section level2">

<h1>Voice onset time</h1>

<p>Perhaps the single most substantial example of a hand-picked feature <span class="cite">Lisker &amp; Abramson (1964)</span></p>

<ul>

<li>Coined in Lisker &amp; Abramson (1964), after a synthesizer parameter which created the percept of (English) voiceless stops

<ul>

<li>Delaying “voice onset” = aspiration</li>

</ul></li>

<li>Building on years of research into parameters of linguistic plosive “voicing” contrasts <span class="cite">Stetson (1951); Liberman, Delattre &amp; Cooper (1952)</span></li>

<li>Building on knowledge of first principles (knowing how plosives are generally produced)</li>

</ul>

<p>Can characterizing laryngeal contrasts in a wide range of languages <span class="cite">Cho &amp; Ladefoged (1999)</span></p>

</div><div id="formants" class="slide section level2">

<h1>Formants</h1>

<p>Formants as a feature are intimately connected to the history of phonetics as a science</p>

<ul>

<li>Gradual refinement of interpretation of formants in terms of articulatory actions <span class="cite">Hermann (1894, 1895); Russell (1929)</span></li>

<li>Source-filter theory: clear physiological, articulatory correlates <span class="cite">Chiba &amp; Kajiyama (1941); Fant (1960)</span></li>

</ul>

<p>Establishment of usefulness in other terms</p>

<ul>

<li>Formant transitions for consonants; variation; formants as <em>perceptually</em> relevant <span class="cite">Potter &amp; Peterson 1948; Peterson &amp; Barney (1952)</span></li>

<li>Bark scale (and others), for better mapping to perceptual space <span class="cite">Zwicker (1961)</span></li>

</ul>

</div><div id="single-features-as-less-than-optimal" class="slide section level2">

<h1>Single features as less than optimal</h1>

<p>Even these two very popular, very validated features don’t necessarily extend well to <em>all</em> related speech phenomena, or cannot characterize the basis of all related phonological contrasts</p>

<ul>

<li>In particular due to language to language variation, or even differences in how a contrastive property is coproduced on various segment types</li>

<li>Sometimes a speech phenomenon does not have clear, easily extracted features in the acoustic signal</li>

</ul>

</div><div id="voice-onset-time-1" class="slide section level2">

<h1>Voice onset time?</h1>

<p>Certain dimensions of “voicing” contrast are not captured using voice onset time alone <span class="cite">see Abramson &amp; Whalen (2017)</span></p>

<ul>

<li>Voiced aspirated or breathy plosives <span class="cite">Davis (1994), Mikuteit &amp; Reetz (2007), Dmitrieva &amp; Dutta (2020)</span></li>

<li>Preaspirated plosives <span class="cite">Löfqvist &amp; Yoshida (1981); Helgason &amp; Ringen (2008)</span></li>

<li>Tense-lax contrasts as in Otomanguean <span class="cite">DiCanio (2012)</span> or Korean <span class="cite">Cho et al. 2002</span></li>

</ul>

</div><div id="nasality" class="slide section level2">

<h1>Nasality?</h1>

<p>Measuring the degree of nasality in vowels has long been a problem for phoneticians, since nasality may be signaled by a huge number of acoustic cues <span class="cite">Styler (2017)</span></p>

<ul>

<li>Nasal formants and antiformants (Styler examines 13 features)</li>

<li>Formant freqs and bandwidths</li>

<li>Spectral tilt, due to more drop-off of high harmonics in nasals</li>

</ul>

<p>Use of each property varies:</p>

<ul>

<li>Vowel-specific effects on formants <span class="cite">Carignan (2018)</span> (“counter-clockwise vowel shift”)</li>

<li>Language-specific acoustics <span class="cite">Styler (2017)</span></li>

</ul>

</div><div id="phonation" class="slide section level2">

<h1>Phonation?</h1>

<p>Another case where simple measures have gradually been shown to be insufficient</p>

<ul>

<li>Traditional: basically one-dimensional, related to glottal opening <span class="cite">Gordon &amp; Ladefoged (2001)</span></li>

<li>But recent study of more languages has shown that voice quality is clearly multi-dimensional <span class="cite">Gerratt &amp; Kreiman (2001); Esposito &amp; Khan (2020); Keating et al (n.d.)</span>, particularly in languages with many phonation types, i.e. !Xóõ <span class="cite">Garellek (2019)</span></li>

</ul>

<p>Ways to measure properties of phonation include:</p>

<ul>

<li>Spectral tilt measures</li>

<li>Formant amplitudes and bandwidths</li>

<li>Electroglottograph measures (contact quotient, open quotient)</li>

</ul>

<p>Different properties are useful in different languages <span class="cite">Brunelle &amp; Kirby (2016)</span></p>

</div><div id="advanced-tongue-root" class="slide section level2">

<h1>Advanced tongue root?</h1>

<p>Perhaps one of the most difficult contrasts to capture acoustically; wide range of acoustic properties have been employed <span class="cite">Fulop et al (1998); Kirkham &amp; Nance (2017); Olejarczuk et al. (2019) </span></p>

<ul>

<li>Frequency and bandwidth of F1</li>

<li>Low harmonic amplitudes and derived measures</li>

<li>Center of gravity; spectral tilt</li>

</ul>

<p>Some reasons for acoustic variation:</p>

<ul>

<li>Underlying cavity shapes may vary from language to language <span class="cite">Kirkham &amp; Nance (2017)</span></li>

<li>Some languages recruit voice quality differences to support <span class="cite">Edmonson &amp; Esling (2006); Guion et al. (2008); Olejarczuk et al. (2019)</span></li>

</ul>

</div>

<div id="feature-selection-discussion" class="title-slide slide section level1"><h1>Feature selection: discussion</h1></div><div id="advantages" class="slide section level2">

<h1>Advantages</h1>

<p>Feature selection is the usual way of working, and it is popular for good reasons</p>

<ul>

<li><em>Ease</em> of use: simple numerical measures are easy to collect and process, which non-trivially makes replication easier

<ul>

<li>Experimental design is easier, since we know the specific, small number of features to focus on</li>

<li>Performance of equipment is better</li>

</ul></li>

<li><em>Interpretability</em>: based on first principles, we know how to interpret variation in that feature

<ul>

<li>Developing <em>theory</em> in tandem</li>

</ul></li>

</ul>

</div><div id="disadvantages" class="slide section level2">

<h1>Disadvantages</h1>

<p>But occasionally leads to some undesirable outcomes, particularly for phonetic phenomena that are less well-understood or harder to model</p>

<ul>

<li>Hand-picking and testing of a large set of features often needed at this stage

<ul>

<li>Formants and VOT took decades to work out</li>

<li>Some acoustic phenomena still being worked out (nasality and phonation in particular)</li>

</ul></li>

</ul>

<p>Researchers may over-apply too few features which don’t work well</p>

<ul>

<li>Ease of use of a particular feature (i.e. VOT) may itself affect the phenomena which are investigated</li>

<li>Researchers will gravitate to certain simple, generally accepted features</li>

</ul>

</div><div id="disadvantages-1" class="slide section level2">

<h1>Disadvantages</h1>

<p>Other types of data are less well suited to feature selection overall</p>

<ul>

<li>Articulatory data based on video or medical scanning: massively <strong>high-dimensional</strong></li>

<li>Huge number of features in the data (in this case, individual pixels; measurements that could be derived from them; etc.)</li>

</ul>

<p>[picture goes here]</p>

</div><div id="alternatives-to-feature-selection" class="slide section level2">

<h1>Alternatives to feature selection</h1>

<p>There is another way to approach problems where feature selection is difficult or impractical, or may not accurately characterize the phenomenon being studied</p>

<ul>

<li>Or to simply speed along feature selection</li>

</ul>

<p>Rather than hand-picking features from data, let the useful features <em>emerge from the data</em></p>

<ul>

<li>“Data-driven” approach</li>

<li>Takes into account all aspects of all the data</li>

<li>Pull out <em>whichever</em> features vary interestingly in the data</li>

</ul>

<p>Practical ways to achieve this: starting in the next lecture</p>

</div><div id="references" class="slide section level2 bib">

<h1>References</h1>

<p>Abramson, A., &amp; Whalen, D. (2017). Voice Onset Time (VOT) at 50: Theoretical and practical issues in measuring voicing distinctions. <i>Journal of Phonetics</i> 63, 75-86. <a href="https://doi.org/10.1016/j.wocn.2017.05.002">DOI</a></p>

<p>Brunelle, M., &amp; Kirby, J. (2016). Tone and phonation in Southeast Asian languages. Language and Linguistics Compass, 10(4), 191-207. <a href="https://doi.org/10.1111/lnc3.12182">DOI</a></p>

<p>Cai, J., Luo, J., Wang, S. &amp; Yang, S. (2018). Feature selection in machine learning: A new perspective. Neurocomputing, 300, 70-79. <a href="https://doi.org/10.1016/j.neucom.2017.11.077">DOI</a></p>

<p>Carignan, C. (2018). Using ultrasound and nasalance to separate oral and nasal contributions to formant frequencies of nasalized vowels. <i>The Journal of the Acoustical Society of America</i>, 143(5), 2588-2601. <a href="https://doi.org/10.1121/1.5034760">DOI</a></p>

<p>Chiba, T. &amp; Kajiyama, M. (1941). <i>The vowel: Its nature and structure</i>. Kaiseikan.</p>

<p>Cho, T. &amp; Ladefoged, P. (1999). Variation and universals in VOT: evidence from 18 languages. <i>Journal of Phonetics</i> 27(2), 207-229. <a href="https://doi.org/10.1006/jpho.1999.0094">DOI</a></p>

<p>Cho, T., Jun, S. &amp; Ladefoged, P. (2002). Acoustic and aerodynamic correlates of Korean stops and fricatives. <i>Journal of Phonetics</i>, 30(2), 193-228. <a href="https://doi.org/10.1006/jpho.2001.0153">DOI</a></p>

<p>Davis, K. (1994). Stop voicing in Hindi. <i>Journal of Phonetics</i>, 22(2), 177-193. <a href="https://doi.org/10.1016/S0095-4470(19)30192-5">DOI</a></p>

<p>DiCanio, C. (2012). The phonetics of fortis and lenis consonants in Itunyoso Trique. <i>International Journal of American Linguistics</i>, 78(2), 239-272. <a href="https://doi.org/10.1086/664481">DOI</a></p>

<p>Dmitrieva, O. &amp; Dutta, I. (2020). Acoustic correlates of the four-way laryngeal contrast in Marathi. Phonetica, 77(3), 209-237. <a href="https://doi.org/10.1159/000501673">DOI</a></p>

<p>Edmondson, J. &amp; Esling, J. (2006). The valves of the throat and their functioning in tone, vocal register and stress: laryngoscopic case studies. <i>Phonology</i>, 23(2), 157-191. <a href="https://doi.org/10.1017/S095267570600087X">DOI</a></p>

<p>Esposito, C. &amp; Khan, S. (2020). The cross‐linguistic patterns of phonation types. Language and Linguistics Compass, 14(12), e12392. <a href="https://doi.org/10.1111/lnc3.12392">DOI</a></p>

<p>Fant, G. (1960). <i>The Acoustic Theory of Speech Production</i>. Moulton.</p>

<p>Fulop, S., Kari, E. &amp; Ladefoged, P. (1998). An acoustic study of the tongue root contrast in Degema vowels. <i>Phonetica</i>, 55(1-2), 80-98. <a href="https://doi.org/10.1159/000028425">DOI</a></p>

<p>Garellek, M. (2019). Acoustic discriminability of the complex phonation system in !Xóõ. <i>Phonetica</i>, 77(2), 1–30. <a href="https://doi.org/10.1159/000494301">DOI</a></p>

<p>Gerratt, B. &amp; Kreiman, J. (2001). Toward a taxonomy of nonmodal phonation. <i>Journal of Phonetics</i>, 29(4), 365-381. <a href="https://doi.org/10.006/jpho.2001.0149">DOI</a></p>

<p>Guion, S., Post, M. &amp; Payne, D. (2004). Phonetic correlates of tongue root vowel contrasts in Maa. <i>Journal of Phonetics</i>, 32(4), 517-542. <a href="https://doi.org/10.1016/j.wocn.2004.04.002">DOI</a></p>

<p>Guyon, I. &amp; Elisseeff, A. (2003). An introduction to variable and feature selection. <i>Journal of Machine Learning Research</i>, 3, 1157-1182. <a href="https://dl.acm.org/doi/abs/10.5555/944919.944968">PDF</a></p>

<p>Helgason, P. &amp; Ringen, C. (2008). Voicing and aspiration in Swedish stops. <i>Journal of Phonetics</i>, 36(4), 607-628. <a href="https://doi.org/10.1016/j.wocn.2008.02.003">DOI</a></p>

<p>Hermann, L. (1895). “Weitere Untersuchungen über das Wesen der Vocale [Further analysis on the characteristics of vowels],” <i>Pflügers Archiv: European Journal of Physiology</i>, 61(4), 169–204.</p>

<p>Hermann, L. (1894). Nachtrag zur Untersuchung der Vocalcurven [Addendum to the investigation of vowel lines]. <i>Archiv für gesamte Physiologie des Menschen und der Tiere</i>, 58, 264–279. <a href="https://zenodo.org/record/2144046#.YfLA2BPML0o">PDF</a></p>

<p>Liu, H. (2011). Feature selection. In Sammut, C. &amp; Webb, G. (eds.), <i>Encyclopedia of Machine Learning</i>, 402-406. Springer.</p>

<p>Keating, P., Kuang, J., Garellek, M., Esposito, C. &amp; Khan, S. (n.d.) A cross-language acoustic space for phonation distinctions. Unpublished manuscript, UCLA. <a href="https://linguistics.ucla.edu/people/keating/Keating-etal_2019_ms.pdf">PDF</a></p>

<p>Kirkham, S. &amp; Nance, C. (2017). An acoustic-articulatory study of bilingual vowel production: Advanced tongue root vowels in Twi and tense/lax vowels in Ghanaian English. <i>Journal of Phonetics</i>, 62, 65-81. <a href="https://doi.org/10.1016/j.wocn.2017.03.004">DOI</a></p>

<p>Liberman, A., Delattre, P. &amp; Cooper, F. (1952). The rôle of selected stimulus variables in the perception of the unvoiced stop consonants. <i>Amer J. Psychol.</i> 65, 497. <a href="https://doi.org/10.2307/1418032">DOI</a></p>

<p>Lisker, L. &amp; Abramson, A. (1964). A cross-language study of voicing in initial stops: acoustical measurements. <i>Word</i> 20, 384-422. <a href="https://doi.org/10.1080/00437956.1964.11659830">DOI</a></p>

<p>Löfqvist A. &amp; Yoshida H. (1981). Laryngeal activity in Icelandic obstruent production. <i>Nordic Journal of Linguistics</i> 4, 1–18. <a href="https://doi.org/10.1017/S0332586500000639">DOI</a></p>

<p>Mikuteit, S. &amp; Reetz, H. (2007). Caught in the ACT: The timing of aspiration and voicing in East Bengali. <i>Language and Speech</i>, 50(2), 247-277. <a href="https://doi.org/10.1177/00238309070500020401">DOI</a></p>

<p>Olejarczuk, P., Otero, M. &amp; Baese-Berk, M. (2019). Acoustic correlates of anticipatory and progressive [ATR] harmony processes in Ethiopian Komo. <i>Journal of Phonetics</i>, 74, 18-41. <a href="https://doi.org/10.1016/j.wocn.2019.01.004">DOI</a></p>

<p>Russell, G. (1929). Mechanism of speech. <i>Journal of the Acoustical Society of America</i>, 1(1), 32–33. <a href="https://doi.org/10.1121/1.1901471">DOI</a></p>

<p>Stetson, R. (1951). <i>Motor phonetics.</i> Amsterdam: North-Holland Publishing Company.</p>

<p>Styler, W. (2017). On the acoustical features of vowel nasality in English and French. <i>The Journal of the Acoustical Society of America</i>, 142(4), 2469-2482. <a href="https://doi.org/10.1121/1.5008854">DOI</a></p>

<p>Zwicker, E. (1961). Subdivision of the audible frequency range into critical bands (Frequenzgruppen). <i>The Journal of the Acoustical Society of America</i>, 33(2), 248-248. <a href="https://doi.org/10.1121/1.1908630">DOI</a></p>

</div>

</body>

</html>
